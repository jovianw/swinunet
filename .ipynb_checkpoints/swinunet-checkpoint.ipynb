{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19096,
     "status": "ok",
     "timestamp": 1708324775374,
     "user": {
      "displayName": "NGKD",
      "userId": "00773922209354261622"
     },
     "user_tz": 360
    },
    "id": "4MdtSq298luC",
    "outputId": "50475c3f-52cf-4fbb-e357-eb783668a347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xV37eWL2GG0l"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnibabel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bl83iyGHGH08"
   },
   "outputs": [],
   "source": [
    "# Paths to your datasets\n",
    "data_path = '/content/drive/MyDrive/Data/NGKDStorage/images/ULS23_Part1/ULS23/novel_data/ULS23_Radboudumc_Bone/images'\n",
    "annotations_path = '/content/drive/MyDrive/Data/NGKDStorage/annotations/ULS23/novel_data/ULS23_Radboudumc_Bone/labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZmXOIkhGJhe"
   },
   "outputs": [],
   "source": [
    "class NiftiDataGenerator(Sequence):\n",
    "    def __init__(self, data_filenames, annotations_filenames, batch_size, data_path, annotations_path, image_size=(256, 256)):\n",
    "        self.data_filenames = data_filenames\n",
    "        self.annotations_filenames = annotations_filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "        self.annotations_path = annotations_path\n",
    "        self.image_size = image_size\n",
    "        self.indexes = self._get_indexes()\n",
    "\n",
    "    def _get_indexes(self):\n",
    "        indexes = []\n",
    "        for i, fname in enumerate(self.data_filenames):\n",
    "            nii_img = nib.load(os.path.join(self.data_path, fname))\n",
    "            num_slices = nii_img.shape[2]\n",
    "            for slice_index in range(num_slices):\n",
    "                indexes.append((i, slice_index))\n",
    "        return indexes\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indexes) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_data = []\n",
    "        batch_annotations = []\n",
    "\n",
    "        for i, slice_index in batch_indexes:\n",
    "            data_filename = self.data_filenames[i]\n",
    "            annotations_filename = self.annotations_filenames[i]\n",
    "\n",
    "            data_nii = nib.load(os.path.join(self.data_path, data_filename))\n",
    "            annotations_nii = nib.load(os.path.join(self.annotations_path, annotations_filename))\n",
    "\n",
    "            data_img = data_nii.get_fdata()[:, :, slice_index]\n",
    "            annotations_img = annotations_nii.get_fdata()[:, :, slice_index]\n",
    "\n",
    "            # Convert grayscale to 3 channels by repeating the slice\n",
    "            data_slice_3ch = np.repeat(data_img[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "            # Resize images (if necessary)\n",
    "            data_resized = resize(data_slice_3ch, self.image_size + (3,), anti_aliasing=True)\n",
    "            annotations_resized = resize(annotations_img, self.image_size, anti_aliasing=True, order=0, preserve_range=True)\n",
    "\n",
    "            # Remove the unwanted dimension safely\n",
    "            if data_resized.shape[-1] == 1:\n",
    "                data_resized = data_resized[..., 0]\n",
    "\n",
    "            batch_data.append(data_resized)\n",
    "            batch_annotations.append(annotations_resized)\n",
    "\n",
    "        return np.array(batch_data), np.array(batch_annotations).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAfwewBTGLUA"
   },
   "outputs": [],
   "source": [
    "# Get the list of filenames for data and annotations\n",
    "data_filenames = [f for f in os.listdir(data_path) if f.endswith('.nii.gz')]\n",
    "annotations_filenames = [f for f in os.listdir(annotations_path) if f.endswith('.nii.gz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEzTImjDGPD5"
   },
   "outputs": [],
   "source": [
    "# Sort the lists to ensure they are aligned\n",
    "data_filenames.sort()\n",
    "annotations_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ogFzagLGQ3U"
   },
   "outputs": [],
   "source": [
    "# Split the filenames into training and validation sets\n",
    "train_data_filenames, val_data_filenames, train_annotations_filenames, val_annotations_filenames = train_test_split(data_filenames, annotations_filenames, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25Arkb3kGaxS"
   },
   "outputs": [],
   "source": [
    "batch_size = 4  # Adjust based on your GPU memory\n",
    "\n",
    "# Create the data generators\n",
    "train_generator = NiftiDataGenerator(\n",
    "    data_filenames=train_data_filenames,\n",
    "    annotations_filenames=train_annotations_filenames,\n",
    "    batch_size=batch_size,\n",
    "    data_path=data_path,\n",
    "    annotations_path=annotations_path\n",
    ")\n",
    "\n",
    "val_generator = NiftiDataGenerator(\n",
    "    data_filenames=val_data_filenames,\n",
    "    annotations_filenames=val_annotations_filenames,\n",
    "    batch_size=batch_size,\n",
    "    data_path=data_path,\n",
    "    annotations_path=annotations_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKXy9y94G17L"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    # Load a pretrained MobileNetV2 model as a base\n",
    "    base_model = MobileNetV2(input_shape=[image_size, image_size, 3], include_top=False)\n",
    "\n",
    "    # Use the activations of these layers\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    # Create the feature extraction model\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "    down_stack.trainable = False\n",
    "\n",
    "    # Define the upsampling layers\n",
    "    up_stack = [\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 4x4 -> 8x8\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 8x8 -> 16x16\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 16x16 -> 32x32\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 32x32 -> 64x64\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 64x64 -> 128x128\n",
    "        layers.UpSampling2D(size=(2, 2)),  # 128x128 -> 256x256\n",
    "    ]\n",
    "\n",
    "    inputs = tf.keras.Input(shape=[image_size, image_size, 3])\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = layers.Conv2DTranspose(\n",
    "        num_classes, 3, strides=2,\n",
    "        padding='same', activation='softmax')  # Use strides=2 to match the original image size if needed\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLP1CMGyKsNt"
   },
   "outputs": [],
   "source": [
    "# Define the size of your images and number of classes\n",
    "image_size = 256  # Size of your input images\n",
    "num_classes = 2   # Two classes: background and lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avU9W_OHMmMG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    intersection = tf.reduce_sum(tf.cast(y_true, tf.float32) * tf.cast(y_pred, tf.float32))\n",
    "    union = tf.reduce_sum(tf.cast(y_true, tf.float32)) + tf.reduce_sum(tf.cast(y_pred, tf.float32))\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "# Custom callback to print the Dice score after each epoch\n",
    "class PrintDiceScoreCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch+1}: Dice Score is {logs['dice_score']:.4f} for training and {logs['val_dice_score']:.4f} for validation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1984,
     "status": "ok",
     "timestamp": 1708329203507,
     "user": {
      "displayName": "NGKD",
      "userId": "00773922209354261622"
     },
     "user_tz": 360
    },
    "id": "h3jgDl-4Ktpg",
    "outputId": "bf5cb564-b1e7-42eb-a2f1-64799b098a35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_26 (Functional)       [(None, 128, 128, 96),       1841984   ['input_28[0][0]']            \n",
      "                              (None, 64, 64, 144),                                                \n",
      "                              (None, 32, 32, 192),                                                \n",
      "                              (None, 16, 16, 576),                                                \n",
      "                              (None, 8, 8, 320)]                                                  \n",
      "                                                                                                  \n",
      " up_sampling2d_78 (UpSampli  (None, 16, 16, 320)          0         ['model_26[0][4]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_52 (Concatenat  (None, 16, 16, 896)          0         ['up_sampling2d_78[0][0]',    \n",
      " e)                                                                  'model_26[0][3]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_79 (UpSampli  (None, 32, 32, 896)          0         ['concatenate_52[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_53 (Concatenat  (None, 32, 32, 1088)         0         ['up_sampling2d_79[0][0]',    \n",
      " e)                                                                  'model_26[0][2]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_80 (UpSampli  (None, 64, 64, 1088)         0         ['concatenate_53[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_54 (Concatenat  (None, 64, 64, 1232)         0         ['up_sampling2d_80[0][0]',    \n",
      " e)                                                                  'model_26[0][1]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_81 (UpSampli  (None, 128, 128, 1232)       0         ['concatenate_54[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenat  (None, 128, 128, 1328)       0         ['up_sampling2d_81[0][0]',    \n",
      " e)                                                                  'model_26[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2  (None, 256, 256, 2)          23906     ['concatenate_55[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1865890 (7.12 MB)\n",
      "Trainable params: 23906 (93.38 KB)\n",
      "Non-trainable params: 1841984 (7.03 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = DeeplabV3Plus(image_size, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[dice_score])\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuHvMbXyMpI6"
   },
   "outputs": [],
   "source": [
    "# Define, compile, and train the model\n",
    "def train_model():\n",
    "    model = None  # Declare model variable first\n",
    "    # Check if a model already exists\n",
    "    model_path = './my_deeplab_model.h5'\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading existing model.\")\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects={'dice_score': dice_score})\n",
    "    else:\n",
    "        print(\"Creating a new model.\")\n",
    "        model = DeeplabV3Plus(image_size, num_classes)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=[dice_score])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=1,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=[PrintDiceScoreCallback()]\n",
    "    )\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(model_path)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzdiWDBXMe_9",
    "outputId": "15e262e3-20ca-4fe8-c6df-adb4e69403ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model.\n",
      " 2264/19040 [==>...........................] - ETA: 10:08:20 - loss: 0.0110 - dice_score: 0.8225"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = train_model()\n",
    "\n",
    "# Plot the Dice score\n",
    "plt.plot(history.history['dice_score'], label='Training Dice Score')\n",
    "plt.plot(history.history['val_dice_score'], label='Validation Dice Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
